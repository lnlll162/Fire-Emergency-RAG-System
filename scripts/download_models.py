#!/usr/bin/env python3
"""
æ¨¡å‹ä¸‹è½½è„šæœ¬
ç”¨äºä¸‹è½½å’Œç¼“å­˜åµŒå…¥æ¨¡å‹ï¼Œè§£å†³ç½‘ç»œè¿æ¥é—®é¢˜
"""

import os
import sys
import logging
from pathlib import Path
from typing import List, Dict, Any
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

try:
    from sentence_transformers import SentenceTransformer
    import torch
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…: {e}")
    print("è¯·è¿è¡Œ: pip install sentence-transformers torch")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ModelDownloader:
    """æ¨¡å‹ä¸‹è½½å™¨"""
    
    def __init__(self):
        self.models_dir = Path("models/embeddings")
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        # æ¨¡å‹é…ç½®
        self.model_configs = [
            {
                'name': 'paraphrase-multilingual-MiniLM-L12-v2',
                'description': 'å¤šè¯­è¨€è½»é‡çº§æ¨¡å‹',
                'size': '~120MB',
                'priority': 1,
                'recommended': True
            },
            {
                'name': 'all-MiniLM-L6-v2',
                'description': 'è‹±æ–‡è½»é‡çº§æ¨¡å‹',
                'size': '~80MB',
                'priority': 2,
                'recommended': True
            },
            {
                'name': 'distiluse-base-multilingual-cased',
                'description': 'å¤šè¯­è¨€åŸºç¡€æ¨¡å‹',
                'size': '~500MB',
                'priority': 3,
                'recommended': False
            },
            {
                'name': 'all-mpnet-base-v2',
                'description': 'é«˜æ€§èƒ½è‹±æ–‡æ¨¡å‹',
                'size': '~400MB',
                'priority': 4,
                'recommended': False
            }
        ]
    
    def download_model(self, model_name: str) -> bool:
        """ä¸‹è½½æŒ‡å®šæ¨¡å‹"""
        try:
            logger.info(f"å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
            model_path = self.models_dir / model_name
            if model_path.exists():
                logger.info(f"æ¨¡å‹ {model_name} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                return True
            
            # ä¸‹è½½æ¨¡å‹
            logger.info(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹ {model_name}...")
            model = SentenceTransformer(model_name)
            
            # æµ‹è¯•æ¨¡å‹
            test_text = "æµ‹è¯•æ–‡æœ¬"
            embedding = model.encode([test_text])
            
            if embedding is not None and len(embedding) > 0:
                logger.info(f"âœ… æ¨¡å‹ {model_name} ä¸‹è½½å¹¶æµ‹è¯•æˆåŠŸ")
                logger.info(f"æ¨¡å‹ç»´åº¦: {embedding.shape[1]}")
                
                # ä¿å­˜æ¨¡å‹ä¿¡æ¯
                self._save_model_info(model_name, True)
                return True
            else:
                logger.error(f"âŒ æ¨¡å‹ {model_name} æµ‹è¯•å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½æ¨¡å‹ {model_name} å¤±è´¥: {str(e)}")
            self._save_model_info(model_name, False, str(e))
            return False
    
    def download_recommended_models(self) -> Dict[str, bool]:
        """ä¸‹è½½æ¨èçš„æ¨¡å‹"""
        results = {}
        recommended_models = [m for m in self.model_configs if m['recommended']]
        
        logger.info("å¼€å§‹ä¸‹è½½æ¨èçš„æ¨¡å‹...")
        
        for model_config in recommended_models:
            model_name = model_config['name']
            logger.info(f"ä¸‹è½½æ¨èæ¨¡å‹: {model_name} ({model_config['description']})")
            results[model_name] = self.download_model(model_name)
        
        return results
    
    def download_all_models(self) -> Dict[str, bool]:
        """ä¸‹è½½æ‰€æœ‰æ¨¡å‹"""
        results = {}
        
        logger.info("å¼€å§‹ä¸‹è½½æ‰€æœ‰æ¨¡å‹...")
        
        for model_config in self.model_configs:
            model_name = model_config['name']
            logger.info(f"ä¸‹è½½æ¨¡å‹: {model_name} ({model_config['description']})")
            results[model_name] = self.download_model(model_name)
        
        return results
    
    def _save_model_info(self, model_name: str, success: bool, error: str = None):
        """ä¿å­˜æ¨¡å‹ä¿¡æ¯"""
        info = {
            "model_name": model_name,
            "success": success,
            "timestamp": datetime.now().isoformat(),
            "error": error
        }
        
        info_file = self.models_dir / f"{model_name}_info.json"
        try:
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(info, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"ä¿å­˜æ¨¡å‹ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    def check_models(self) -> Dict[str, Dict[str, Any]]:
        """æ£€æŸ¥å·²ä¸‹è½½çš„æ¨¡å‹"""
        results = {}
        
        for model_config in self.model_configs:
            model_name = model_config['name']
            model_path = self.models_dir / model_name
            
            info = {
                "name": model_name,
                "description": model_config['description'],
                "size": model_config['size'],
                "downloaded": model_path.exists(),
                "recommended": model_config['recommended']
            }
            
            # æ£€æŸ¥æ¨¡å‹ä¿¡æ¯æ–‡ä»¶
            info_file = self.models_dir / f"{model_name}_info.json"
            if info_file.exists():
                try:
                    with open(info_file, 'r', encoding='utf-8') as f:
                        model_info = json.load(f)
                    info.update(model_info)
                except Exception as e:
                    logger.warning(f"è¯»å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {str(e)}")
            
            results[model_name] = info
        
        return results
    
    def print_status(self):
        """æ‰“å°æ¨¡å‹çŠ¶æ€"""
        models = self.check_models()
        
        print("\n" + "="*60)
        print("ğŸ“Š æ¨¡å‹ä¸‹è½½çŠ¶æ€")
        print("="*60)
        
        for model_name, info in models.items():
            status = "âœ… å·²ä¸‹è½½" if info['downloaded'] else "âŒ æœªä¸‹è½½"
            recommended = "â­ æ¨è" if info['recommended'] else ""
            
            print(f"{model_name}")
            print(f"  çŠ¶æ€: {status} {recommended}")
            print(f"  æè¿°: {info['description']}")
            print(f"  å¤§å°: {info['size']}")
            
            if info.get('timestamp'):
                print(f"  æ—¶é—´: {info['timestamp']}")
            
            if info.get('error'):
                print(f"  é”™è¯¯: {info['error']}")
            
            print()
    
    def cleanup_failed_models(self):
        """æ¸…ç†å¤±è´¥çš„æ¨¡å‹ä¸‹è½½"""
        logger.info("æ¸…ç†å¤±è´¥çš„æ¨¡å‹ä¸‹è½½...")
        
        for model_config in self.model_configs:
            model_name = model_config['name']
            model_path = self.models_dir / model_name
            info_file = self.models_dir / f"{model_name}_info.json"
            
            # å¦‚æœæ¨¡å‹ç›®å½•å­˜åœ¨ä½†ä¿¡æ¯æ–‡ä»¶æ˜¾ç¤ºå¤±è´¥ï¼Œåˆ™æ¸…ç†
            if model_path.exists() and info_file.exists():
                try:
                    with open(info_file, 'r', encoding='utf-8') as f:
                        info = json.load(f)
                    
                    if not info.get('success', False):
                        logger.info(f"æ¸…ç†å¤±è´¥çš„æ¨¡å‹: {model_name}")
                        import shutil
                        shutil.rmtree(model_path, ignore_errors=True)
                        info_file.unlink(missing_ok=True)
                        
                except Exception as e:
                    logger.warning(f"æ¸…ç†æ¨¡å‹ {model_name} å¤±è´¥: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ¨¡å‹ä¸‹è½½è„šæœ¬")
    parser.add_argument("--model", help="ä¸‹è½½æŒ‡å®šæ¨¡å‹")
    parser.add_argument("--recommended", action="store_true", help="ä¸‹è½½æ¨èæ¨¡å‹")
    parser.add_argument("--all", action="store_true", help="ä¸‹è½½æ‰€æœ‰æ¨¡å‹")
    parser.add_argument("--check", action="store_true", help="æ£€æŸ¥æ¨¡å‹çŠ¶æ€")
    parser.add_argument("--cleanup", action="store_true", help="æ¸…ç†å¤±è´¥çš„æ¨¡å‹")
    
    args = parser.parse_args()
    
    downloader = ModelDownloader()
    
    if args.check:
        downloader.print_status()
        return
    
    if args.cleanup:
        downloader.cleanup_failed_models()
        return
    
    if args.model:
        success = downloader.download_model(args.model)
        if success:
            print(f"âœ… æ¨¡å‹ {args.model} ä¸‹è½½æˆåŠŸ")
        else:
            print(f"âŒ æ¨¡å‹ {args.model} ä¸‹è½½å¤±è´¥")
            sys.exit(1)
    
    elif args.recommended:
        results = downloader.download_recommended_models()
        success_count = sum(1 for success in results.values() if success)
        total_count = len(results)
        
        print(f"\nğŸ“Š æ¨èæ¨¡å‹ä¸‹è½½å®Œæˆ: {success_count}/{total_count}")
        downloader.print_status()
        
        if success_count == 0:
            sys.exit(1)
    
    elif args.all:
        results = downloader.download_all_models()
        success_count = sum(1 for success in results.values() if success)
        total_count = len(results)
        
        print(f"\nğŸ“Š æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆ: {success_count}/{total_count}")
        downloader.print_status()
        
        if success_count == 0:
            sys.exit(1)
    
    else:
        print("è¯·æŒ‡å®šæ“ä½œå‚æ•°:")
        print("  --check        æ£€æŸ¥æ¨¡å‹çŠ¶æ€")
        print("  --recommended  ä¸‹è½½æ¨èæ¨¡å‹")
        print("  --all          ä¸‹è½½æ‰€æœ‰æ¨¡å‹")
        print("  --model NAME   ä¸‹è½½æŒ‡å®šæ¨¡å‹")
        print("  --cleanup      æ¸…ç†å¤±è´¥çš„æ¨¡å‹")


if __name__ == "__main__":
    main()
